# Usability 2: OSCER homepage and report activities findings

## Intro
This document outlines the findings and recommendations derived from the moderated usability testing of the OSCER landing page and activity reporting flow. The primary goal was to determine if users could successfully navigate the initial entry points, understand the program, and submit proof of activity without significant friction.

## Methodology
* **Format:** Moderated usability testing with 5 participants.
* **Scenarios:** Participants were asked to evaluate the homepage, and report activities.
* **Key Tasks:**
  * Navigate the homepage to find the exemption and reporting sections.
  * Interpret the "Community Engagement" requirement.
  * Complete the activity reporting stepper, including uploading documentation.
  * Identify and react to pre-filled (external) data within the flow.
⠀
## Key Insights
### “Community Engagement" remains a nebulous term without thorough explanation
While participants understood the concept after reading the full explanation in the “about reporting activities” section, the phrase is confusing on its own. There is a clear need to define this term more explicitly throughout the user journey.

### The Document uploader is easier to use, but there is still opportunity for improvement
 All users successfully selected and uploaded a document without help. However, we found that gathering proof varied in ease. Those who have access to payroll information from their employer found the process to be fairly simple, however for a self employed participant the burden was much higher. They must collect multiple documents, redact sensitive info, and follow strict naming conventions, which feels cumbersome compared to traditional payroll users.

### External data lacks transparency
When external system data appeared, participants were confused about where it came from. Guesses ranged from the initial application onboarding, to employer reporting, indicating a lack of clarity on how the system "found" their hours. 

## Secondary Insights.
* **Homepage navigation is seamless:** All users found the exemption page and the reporting flow without trouble; the "About" sections provide helpful context for the portal’s purpose.
* **Disabled state tooltips may be invisible:** About half of the users saw the tooltip when the "upload" button was disabled, but none commented on it, making it unclear if the guidance is actually being read. That said, no users erroneously clicked on the “Upload documents” button before a document was selected, which is an improvement from what we saw in the first research sprint.
* **Minor usability issues in the stepper:** Most users navigated the "Activity Type" page easily, though one user missed that there were two distinct questions on the screen. Additionally, there is slight confusion regarding specific reporting timeframes (e.g., the exact start/end dates of the reporting period).
* **Trust is tied to official branding:** Participants noted a lack of "government feel." One user explicitly requested "dog whistle" branding—like a Medicaid or State of California logo—to feel secure that the site isn't a scam.
⠀
## Opportunities
### Add more contextual guidance 
Use progressive disclosure in the stepper to further explain what types of activities are accepted, document/proof requirements, reporting period timelines, and external data. 

### Branding for Trust
Explore how customizations/theming with official state or agency logos and/or branding can verify the site's authenticity and build user confidence.

### Streamline Document Proof
Explore how Doc AI can assist with some of the pain points mentioned with gathering proof in order to lower the barrier for individuals that need to manually submit their proof.

### Homepage Utility
Continue exploring layout variations that allow the homepage to serve as a "quick glance" dashboard for returning users.
